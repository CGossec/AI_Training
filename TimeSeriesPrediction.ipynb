{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Shared",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGYenFtnKW3P"
      },
      "source": [
        "## Download Dataset and Unzip it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J03b0DOklrZ-",
        "outputId": "5c100563-4126-46d7-fc4e-077d6d336a45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!unzip \"df.zip\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  df.zip\n",
            "  inflating: df.csv                  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GyjzwWJKbwN"
      },
      "source": [
        "## Import Librairies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5q2aYsRm7Pi",
        "outputId": "20fa8595-3a30-4010-ab6a-fa3f248fab72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from statsmodels.graphics.tsaplots import plot_acf"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPmWq3C9nnGK"
      },
      "source": [
        "# Data Preparation\n",
        "\n",
        "1. read the csv, parse dates and set the index column to the date column (can all be in one function call)\n",
        "2. groupy the dataframe by year and month and sum\n",
        "3. set the column name to \"value\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VGiTDjunH9O"
      },
      "source": [
        "### FIX ME\n",
        "df = pd.read_csv(\"df.csv\")\n",
        "### !FIX ME"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9eLp5konWP7"
      },
      "source": [
        "df.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxeLitcD54bt"
      },
      "source": [
        "plot_acf(df[\"value\"].dropna(), lags=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8JStC2Wns9k"
      },
      "source": [
        "## Making the data stationary\n",
        "\n",
        "In order our models to work, we need to make sure our data is stationary.\n",
        "\n",
        "Here are the steps that you will need to follow:\n",
        "- compute the log of the data\n",
        "- differencing to get month to month variation\n",
        "- differencing again to remove seasonality (approx. 12 months lag)\n",
        "\n",
        "Again, those steps can be completed with only one function call using pandas.DataFrame features.\n",
        "\n",
        "https://pandas.pydata.org/docs/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwXH5FSJnfy_"
      },
      "source": [
        "def check_stationarity(series):\n",
        "    result = adfuller(series)\n",
        "    print('Augmented Dickey-Fuller Test:')\n",
        "    labels = ['ADF Test Statistic', 'p-value', 'Number of Lags Used', 'Number of Observations Used']\n",
        "    for value, label in zip(result, labels):\n",
        "        print(f'{label} : {value}')\n",
        "    if result[1] <= 0.05:\n",
        "        print(\"Data is stationary\")\n",
        "    else:\n",
        "        print(\"Data is not stationary\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd4i6jZ3oTDL"
      },
      "source": [
        "### FIX ME\n",
        "##\n",
        "### !FIX ME"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaZN15pZoY2x",
        "outputId": "69c517a3-17ac-42c2-acbf-4485e99528fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "check_stationarity(df_testing[\"value\"].dropna())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Augmented Dickey-Fuller Test:\n",
            "ADF Test Statistic : -5.225226609716364\n",
            "p-value : 7.807176920050943e-06\n",
            "Number of Lags Used : 3\n",
            "Number of Observations Used : 55\n",
            "Data is stationary\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mM9u2CD6Hsz"
      },
      "source": [
        "###\n",
        "# Here you can plot the autocorrelation diagram again to see the difference\n",
        "###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKV6QQTLr0r_"
      },
      "source": [
        "## Computing the AR(p) model\n",
        "\n",
        "We need a function that takes a value of p (remember the slides) and a dataframe.\n",
        "\n",
        "It should return a tuple containing: (rmse, p, theta, intercept of the regression, the dataframe with prediction included)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaPgHUW30Qe1"
      },
      "source": [
        "def ar(p, df):\n",
        "    \"\"\"\n",
        "    To make things easier, you will need to create as many columns as necessary to perform the regression.\n",
        "    If the autoregressive order (p) is 2, you will need to add 2 columns, one with a shift of 1, and the other with a shift\n",
        "    of 2.\n",
        "\n",
        "    You then split the dataset into 2 parts: train and test (80% for train and the rest for test).\n",
        "\n",
        "    Then you will drop the nan values, because this won't work with the regression.\n",
        "\n",
        "    You will train the linear regression, get the coefficients and the intercept.\n",
        "\n",
        "    Then create a new column \"prediction\" in your train and test datasets that will\n",
        "    be filled with the predicted values.\n",
        "\n",
        "    You compute the RMSE. You can use the mean_squared_error import above not to waste time on it.\n",
        "    Of course you can write your own.\n",
        "\n",
        "    Return [rmse, p, coefficients of the regression, intercept, pd.concat([train, test])]\n",
        "\n",
        "    The sets need to be returned because we are using it later.\n",
        "    \"\"\"\n",
        "    data = df.copy()\n",
        "    ###\n",
        "    # FIX ME\n",
        "    ###\n",
        "    return [rmse, p, lr.coef_.T, lr.intercept_, pd.concat([train, test])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCiXnGyl6U6M"
      },
      "source": [
        "best_rmse = 100000000\n",
        "chosen_p  = -1\n",
        "\n",
        "### FIX ME\n",
        "# Iterate on values of p and take the best (lower RMSE).\n",
        "### !FIX ME"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BlfFCuB64_Y"
      },
      "source": [
        "[rmse, _, theta, intercept, result_prediction_df] = ar(chosen_p, pd.DataFrame(df_testing[\"value\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7-wo1B38eGL"
      },
      "source": [
        "result_prediction_df[[\"value\", \"prediction\"]].plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8GYpUzbr6de"
      },
      "source": [
        "## Computing the MA model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTf06DBA5klQ"
      },
      "source": [
        "def ma(q, df):\n",
        "    \"\"\"\n",
        "    The MA function is extremely similar to the AR function.\n",
        "\n",
        "    It is another linear regression but on residual data instead.\n",
        "    \"\"\"\n",
        "    data = df.copy()\n",
        "    ###\n",
        "    # FIX ME\n",
        "    ###\n",
        "    return [rmse, q, lr.coef_.T, lr.intercept_, pd.concat([train, test])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ttAxTqw9EkB"
      },
      "source": [
        "### FIX ME\n",
        "# Here you generate the residuals data by substracting the AR(p) prediction to the true value\n",
        "### !FIX ME\n",
        "\n",
        "\n",
        "residuals = pd.DataFrame()\n",
        "residuals[\"residual\"] = result_prediction_df[\"value\"] - result_prediction_df[\"prediction\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfBLXDMZ9VrK"
      },
      "source": [
        "# The following function will display the distribution of the residual\n",
        "\n",
        "residuals.plot(kind=\"kde\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQLoxEhp9jL4"
      },
      "source": [
        "best_rmse = 100000000\n",
        "chosen_q  = -1\n",
        "\n",
        "### FIX ME\n",
        "# Again iterate on values of q and take the best (lower RMSE).\n",
        "### !FIX ME"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOIfBcoq9zY-"
      },
      "source": [
        "[rmse, _, theta, intercept, result_residuals_df] = ma(chosen_q, pd.DataFrame(residuals[\"residual\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpRlg161Axwc"
      },
      "source": [
        "result_residuals_df[[\"residual\", \"prediction\"]].plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrlM1EoLr81r"
      },
      "source": [
        "## Forecasting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVMhb112CAnA"
      },
      "source": [
        "result_prediction_df[\"prediction\"] += result_residuals_df[\"prediction\"]\n",
        "result_prediction_df[[\"value\", \"prediction\"]].plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMMaASjer-pn"
      },
      "source": [
        "## Back to the original scale\n",
        "\n",
        "We simply backtrack the operations we performed to make the data stationary so we get back to the original scale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8JD9hDOpLxQ"
      },
      "source": [
        "results = result_prediction_df.copy()\n",
        "results[\"value\"] += np.log(df).shift(1)[\"value\"]\n",
        "results[\"value\"] += np.log(df).diff().shift(12)[\"value\"]\n",
        "results[\"value\"] = np.exp(results[\"value\"])\n",
        "results[\"prediction\"] += np.log(df).shift(1)[\"value\"]\n",
        "results[\"prediction\"] += np.log(df).diff().shift(12)[\"value\"]\n",
        "results[\"prediction\"] = np.exp(results[\"prediction\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKskGv7IG8Ic"
      },
      "source": [
        "results[[\"value\", \"prediction\"]].plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSnnyI_JHRbN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}